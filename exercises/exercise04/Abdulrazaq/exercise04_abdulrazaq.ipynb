{"cells":[{"cell_type":"markdown","id":"64cfc94b-7f4c-44d0-a738-dcf75ca56307","metadata":{"id":"64cfc94b-7f4c-44d0-a738-dcf75ca56307"},"source":["Urban Data Science & Smart Cities <br>\n","URSP688Y <br>\n","Instructor: Chester Harvey <br>\n","Urban Studies & Planning <br>\n","National Center for Smart Growth <br>\n","University of Maryland"]},{"cell_type":"markdown","id":"40140710-dbbb-4249-99bb-bb317297a1cd","metadata":{"id":"40140710-dbbb-4249-99bb-bb317297a1cd"},"source":["[<img src=\"https://colab.research.google.com/assets/colab-badge.svg\">](https://colab.research.google.com/github/ncsg/ursp688y_sp2024/blob/main/exercises/exercise04/exercise04.ipynb)"]},{"cell_type":"markdown","id":"4dbe22dc-a58d-4a1b-a106-dd923f988e5b","metadata":{"id":"4dbe22dc-a58d-4a1b-a106-dd923f988e5b"},"source":["# Exercise 4 (in Two Parts)\n","\n","# The Data Viz Part\n","\n","Next week is Data Visualization week. This is one of my favorite topics, in part because we get to look at lots of pictures, and in part because it provides an excuse for some very lighthearted competition.\n","\n","In prep for next week, part of your exercise is to find an example of either an _excellent_ or _terrible_ data visualization. We will vote on the best (and worst) in each category, and the winner gets a small (tasty) prize.\n","\n","Please find an example of a data visualization that is either _very effective_ or _terribly ineffective_ in communicating an interesting finding from data. Here are a few ground rules:\n","- One figure only: We should be able to see the whole thing at once on a projector screen.\n","- Static images only: If you find something dynamic or interactive that you _must_ submit, please take a screenshot.\n","- Do the reading first: Tufte will give you some ideas for what makes visualizations good or bad\n","- No examples from Tufte. Gotta work a little bit.\n","\n","Please either paste a link to your image in the text cell below (can you figure out how to get markdown to display the image?) or add an image file to your PR.\n","- Please label it clearly as \"good\" or \"bad\" so we know which race you're in.\n","- Please write a couple bullets about why it's good or bad. This is your pitch (we can haggle about it in class, too.)"]},{"cell_type":"markdown","id":"0a728881-d6ad-43de-a173-9ef8724e0997","metadata":{"id":"0a728881-d6ad-43de-a173-9ef8724e0997"},"source":["## Good/Bad (please choose one and delete the other)\n","- Why\n","- Some more why\n","- Any more?\n","\n","***** Put image link or insert image here *****"]},{"cell_type":"markdown","source":[],"metadata":{"id":"uVMzCVZACp7V"},"id":"uVMzCVZACp7V"},{"cell_type":"markdown","id":"c1181b6f-7d2f-4c59-98bf-6940085bc1e6","metadata":{"id":"c1181b6f-7d2f-4c59-98bf-6940085bc1e6"},"source":["# The Programming Part\n","\n","## Problem\n","\n","In [Exercise 3](https://github.com/ncsg/ursp688y_sp2024/blob/main/exercises/exercise03/exercise03.ipynb), you examined how many affordable housing units available to households up to 60% AMI were planned within each ward in Washington, D.C.\n","\n","The bonus problem was to calculate which wards were producing a _disproportionately_ large and small number of housing units given their populations.\n","\n","This week, please reproduce this analysis, <ins>including</ins> the bonus part, using some of your new data loading, joining, and module-building skills.\n","\n","Please write a program that:\n","\n","- Loads the affordable housing project data from `affordable_housing.csv`\n","- Loads the ward populations from `wards_from_2022.csv`\n","- Joins the population data to the affordable housing data\n","- Calculates which wards are producing disproportionately large and small number of housing units given their populations\n","- Completes all of this data loading and processing within a function (or a series of functions called by a single main function)\n","- Stores that function (and any related functions) in a module\n","- Calls the main function in the exercise notebook to return table or other summary or results\n","\n","## Data\n","\n","CSVs for both required data tables are included on GitHub at `exercises/exercise04`.\n","\n","Please consult the city's database of [affordable housing](https://opendata.dc.gov/datasets/DCGIS::affordable-housing/about) projects and [ward demographic](https://opendata.dc.gov/datasets/DCGIS::wards-from-2022/about) data.\n","\n","Bonus: find, download, and use more recent ward population data. (Remember to include it in your PR.) My cursory search found data as late as 2022.\n","\n","## New instructions for submitting a PR with multiple files\n","\n","Because you'll be working with multiple files, PRs become _slightly_ more complicated, so we're graduating to a new 'mini-repository' pattern:\n","- Make a new folder in `exercises/exercise04` with your last name (just like the suffix for your notebook file)\n","- Upload your notebook file, also appropriately named, into that folder\n","- Upload any other files you make/use, including `.py` and `.csv` files, into that folder, so everything is together in the same place\n","\n","Ultimately, this will look a bit like this:\n","```\n","── exercises\n","    ├── exercise04\n","        ├── harvey\n","            ├── exercise04_harvey.ipynb\n","            ├── affordable_housing_calcs.py\n","            ├── affordable_housing.csv\n","            └── wards_from_2022.csv\n","```\n","\n","**NOTE:** Yes, I realize this is a bit redundant because everyone will have copies of the same CSV files. This would never be a good idea for production coding--we would have one `data` directory, and everyone would draw from the same data. However, there are two reasons for all these copies in this case:\n","1. It's good practice to build a repository with all the parts your code needs to run.\n","    - In later weeks, when you  _don't_ all have the same data, it won't seem as redundant.\n","3. Having everything in one folder will make it easy for me to run your code on my computer.\n","\n","## Hints\n","- You may want to join the population data _after_ summarizing the affordable housing data (i.e., join populations to sums of units). However, I could also see an approach where you join at the beginning, then aggregate the population column with a method called `first`\n","\n"]},{"cell_type":"code","source":["#get to the data directory /  load data from directory\n","import os\n","os.getcwd()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"E-qTBCEXGtve","executionInfo":{"status":"ok","timestamp":1709601739536,"user_tz":300,"elapsed":122,"user":{"displayName":"Sururah Bisola Abdulrazaq","userId":"11705825929113034451"}},"outputId":"acdb9af7-d056-4fd1-a1ad-4a8161d03aa7"},"id":"E-qTBCEXGtve","execution_count":177,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/.shortcut-targets-by-id/1m3vxo9-OfgjN1ZSn2umVu3lB4xG0HKiQ/ursp688y_shared_data'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":177}]},{"cell_type":"code","source":["#what is actually in the directory\n","os.listdir()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0FgXTfwQiLF","executionInfo":{"status":"ok","timestamp":1709598391061,"user_tz":300,"elapsed":121,"user":{"displayName":"Sururah Bisola Abdulrazaq","userId":"11705825929113034451"}},"outputId":"5fb2019b-87e4-477b-e095-be39be7ebe92"},"id":"B0FgXTfwQiLF","execution_count":137,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['affordable_housing.csv',\n"," '.ipynb_checkpoints',\n"," '__pycache__',\n"," 'affordable_housing_with_ward_pops (1).csv',\n"," 'affordable_housing_with_ward_pops_test.csv',\n"," 'demo04.py',\n"," 'affordable_housing_calcs_sanford_v2.py',\n"," 'wards_from_2022.csv',\n"," 'data_processing_module.py',\n"," 'wards_from_2022.gsheet',\n"," 'affordable_housing_with_ward_pops.csv',\n"," 'curless_affordable_housing_with_ward.csv',\n"," 'affordable_housing_with_ward_pops_Bardsley3.csv',\n"," 'affordable_housing.gsheet',\n"," 'Copy of affordable_housing.csv',\n"," 'housing_count_fahmi.py']"]},"metadata":{},"execution_count":137}]},{"cell_type":"code","source":[],"metadata":{"id":"hOCYQ-XlNqtU"},"id":"hOCYQ-XlNqtU","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"x7qU0D7YMxg5","executionInfo":{"status":"ok","timestamp":1709602112919,"user_tz":300,"elapsed":117,"user":{"displayName":"Sururah Bisola Abdulrazaq","userId":"11705825929113034451"}}},"id":"x7qU0D7YMxg5","execution_count":182,"outputs":[]},{"cell_type":"code","execution_count":183,"id":"270729b1-57eb-429e-92e4-2320838f2415","metadata":{"id":"270729b1-57eb-429e-92e4-2320838f2415","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709602115306,"user_tz":300,"elapsed":779,"user":{"displayName":"Sururah Bisola Abdulrazaq","userId":"11705825929113034451"}},"outputId":"7d840b85-42da-455a-ce16-49f4569b70a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#mount drive to colab\n","from google.colab import drive\n","drive.mount( '/content/drive')\n"]},{"cell_type":"code","source":["# set working directory\n","wd_path = '/content/drive/MyDrive/ursp688y_shared_data'\n","os.chdir(wd_path)\n","\n","print(f'cwd:{os.getcwd()}')\n","\n","os.path.isfile('affordable_housing.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"34BU8tYQIAbN","executionInfo":{"status":"ok","timestamp":1709601741823,"user_tz":300,"elapsed":149,"user":{"displayName":"Sururah Bisola Abdulrazaq","userId":"11705825929113034451"}},"outputId":"26f62fcd-a802-4a81-c9ff-aa90554d5e42"},"id":"34BU8tYQIAbN","execution_count":178,"outputs":[{"output_type":"stream","name":"stdout","text":["cwd:/content/drive/.shortcut-targets-by-id/1m3vxo9-OfgjN1ZSn2umVu3lB4xG0HKiQ/ursp688y_shared_data\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":178}]},{"cell_type":"code","source":[" # Export merged data to a CSV file\n"," def merge_data():\n","    merge_data =  merged_data.to_csv(\"merged_data.csv\", index=False)  # Specify index=False to exclude row numbers\n","    return merged_data"],"metadata":{"id":"Mx9qZCXG4Is3","executionInfo":{"status":"ok","timestamp":1709602253157,"user_tz":300,"elapsed":129,"user":{"displayName":"Sururah Bisola Abdulrazaq","userId":"11705825929113034451"}}},"id":"Mx9qZCXG4Is3","execution_count":1,"outputs":[]},{"cell_type":"code","source":["#Function to calculate and identify disproportionate units\n","def calculate_disproportionate_units(merged_data):\n","    # Calculate housing units per capita\n","    merged_data['housing_units_per_capita'] = merged_data['TOTAL_AFFORDABLE_UNITS'] / merged_data['POP100']\n","\n","    # Calculate mean housing units per capita across all wards\n","    mean_units_per_capita = merged_data['housing_units_per_capita'].mean()\n","\n","    # Calculate standard deviation of housing units per capita across all wards\n","    std_units_per_capita = merged_data['housing_units_per_capita'].std()\n","\n","    # Define threshold for disproportionately large/small housing units per capita\n","    threshold = 1.5\n","\n","    # Identify disproportionately large and small wards\n","    disproportionately_large = merged_data[merged_data['housing_units_per_capita'] > (mean_units_per_capita + threshold * std_units_per_capita)]\n","    disproportionately_small = merged_data[merged_data['housing_units_per_capita'] < (mean_units_per_capita - threshold * std_units_per_capita)]\n","\n","    return disproportionately_large, disproportionately_small"],"metadata":{"id":"wF1iuT3fNIV0","executionInfo":{"status":"ok","timestamp":1709598719714,"user_tz":300,"elapsed":167,"user":{"displayName":"Sururah Bisola Abdulrazaq","userId":"11705825929113034451"}}},"id":"wF1iuT3fNIV0","execution_count":158,"outputs":[]},{"cell_type":"code","source":["# Call  main function\n","#Main function will call all other functions sequentially\n","def main():\n","    # Load data\n","    affordable_housing_data, ward_population_data = load_data()\n","\n","    # Join data\n","    merged_data = join_data(affordable_housing_data, ward_population_data)\n","\n","    # Calculate disproportionately large and small housing units\n","    disproportionately_large, disproportionately_small = calculate_disproportionate_units(merged_data)\n","\n","   # Export disproportionately large and small dataframes to CSV files\n","    disproportionately_large.to_csv(\"disproportionately_large.csv\", index=False)\n","    disproportionately_small.to_csv(\"disproportionately_small.csv\", index=False)\n","    return disproportionately_large, disproportionately_small"],"metadata":{"id":"t2_i7wsNNNYP","executionInfo":{"status":"ok","timestamp":1709599021173,"user_tz":300,"elapsed":137,"user":{"displayName":"Sururah Bisola Abdulrazaq","userId":"11705825929113034451"}}},"id":"t2_i7wsNNNYP","execution_count":163,"outputs":[]},{"cell_type":"code","source":["import housing\n","\n","from google.colab import drive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"ey1DqxU9MDf1","executionInfo":{"status":"error","timestamp":1709601914367,"user_tz":300,"elapsed":138,"user":{"displayName":"Sururah Bisola Abdulrazaq","userId":"11705825929113034451"}},"outputId":"705fde33-7b41-4c9a-939e-63b1718566cb"},"id":"ey1DqxU9MDf1","execution_count":181,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'housing'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-181-cd312b2301f6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhousing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'housing'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["#Not exactly proud of this process but learned a lot in the process\n","if __name__ == \"__main__\":\n","    disproportionately_large, disproportionately_small = main()\n","    print(\"Wards producing disproportionately large number of housing units:\")\n","    print(disproportionately_large)\n","    print(\"Wards producing disproportionately small number of housing units:\")\n","    print(disproportionately_small)\n",""],"metadata":{"id":"qjjuz1EMNULP"},"id":"qjjuz1EMNULP","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[{"file_id":"14Pv6nF9dX5cjDkEc5qgr3ipezl7LjAwN","timestamp":1709578691534},{"file_id":"https://github.com/ncsg/ursp688y_sp2024/blob/main/exercises/exercise04/exercise04.ipynb","timestamp":1708911582667}]}},"nbformat":4,"nbformat_minor":5}